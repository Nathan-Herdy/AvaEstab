{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "      <th>Age</th>\n",
       "      <th>AgeGroup</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>BMI</th>\n",
       "      <th>FootLen</th>\n",
       "      <th>Nationality</th>\n",
       "      <th>SkinColor</th>\n",
       "      <th>...</th>\n",
       "      <th>y_Mean_Resultant_Speed_cop - Closed - Foam</th>\n",
       "      <th>y_fpcntile50_cop - Closed - Foam</th>\n",
       "      <th>y_fpcntile95_cop - Closed - Foam</th>\n",
       "      <th>y_Peaky_Frequency_cop - Closed - Foam</th>\n",
       "      <th>y_Mean_Frequency_cop - Closed - Foam</th>\n",
       "      <th>y_Total_power_cop - Closed - Foam</th>\n",
       "      <th>APA</th>\n",
       "      <th>RPC</th>\n",
       "      <th>SO</th>\n",
       "      <th>DG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>Young</td>\n",
       "      <td>0</td>\n",
       "      <td>157.5</td>\n",
       "      <td>54.20</td>\n",
       "      <td>21.849332</td>\n",
       "      <td>21.80</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>Yellow</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026691</td>\n",
       "      <td>0.177778</td>\n",
       "      <td>0.844444</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.255995</td>\n",
       "      <td>0.154036</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>27.583333</td>\n",
       "      <td>Young</td>\n",
       "      <td>0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>44.00</td>\n",
       "      <td>18.552876</td>\n",
       "      <td>22.45</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>Pardo/Brown</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037090</td>\n",
       "      <td>0.255556</td>\n",
       "      <td>0.511111</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.264554</td>\n",
       "      <td>0.418301</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>36.916667</td>\n",
       "      <td>Young</td>\n",
       "      <td>1</td>\n",
       "      <td>161.7</td>\n",
       "      <td>63.40</td>\n",
       "      <td>24.247626</td>\n",
       "      <td>23.10</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>White</td>\n",
       "      <td>...</td>\n",
       "      <td>0.047679</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.280833</td>\n",
       "      <td>0.512078</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>61.750000</td>\n",
       "      <td>Old</td>\n",
       "      <td>1</td>\n",
       "      <td>164.0</td>\n",
       "      <td>68.35</td>\n",
       "      <td>25.412701</td>\n",
       "      <td>24.70</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>Pardo/Brown</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066223</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.577778</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.214622</td>\n",
       "      <td>1.880497</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>18.333333</td>\n",
       "      <td>Young</td>\n",
       "      <td>0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>56.45</td>\n",
       "      <td>21.509678</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>White</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046808</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.188889</td>\n",
       "      <td>0.318833</td>\n",
       "      <td>0.413409</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>159</td>\n",
       "      <td>24.750000</td>\n",
       "      <td>Young</td>\n",
       "      <td>0</td>\n",
       "      <td>153.5</td>\n",
       "      <td>62.05</td>\n",
       "      <td>26.334497</td>\n",
       "      <td>21.65</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>White</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038548</td>\n",
       "      <td>0.311111</td>\n",
       "      <td>0.988889</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.382401</td>\n",
       "      <td>0.201918</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>160</td>\n",
       "      <td>23.583333</td>\n",
       "      <td>Young</td>\n",
       "      <td>0</td>\n",
       "      <td>161.5</td>\n",
       "      <td>56.55</td>\n",
       "      <td>21.681412</td>\n",
       "      <td>22.75</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>White</td>\n",
       "      <td>...</td>\n",
       "      <td>0.052360</td>\n",
       "      <td>0.188889</td>\n",
       "      <td>0.688889</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.243581</td>\n",
       "      <td>0.834123</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>161</td>\n",
       "      <td>25.333333</td>\n",
       "      <td>Young</td>\n",
       "      <td>0</td>\n",
       "      <td>167.7</td>\n",
       "      <td>60.55</td>\n",
       "      <td>21.530198</td>\n",
       "      <td>23.75</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>White</td>\n",
       "      <td>...</td>\n",
       "      <td>0.068107</td>\n",
       "      <td>0.377778</td>\n",
       "      <td>1.177778</td>\n",
       "      <td>0.211111</td>\n",
       "      <td>0.421260</td>\n",
       "      <td>0.516105</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>162</td>\n",
       "      <td>24.083333</td>\n",
       "      <td>Young</td>\n",
       "      <td>1</td>\n",
       "      <td>183.5</td>\n",
       "      <td>63.20</td>\n",
       "      <td>18.769165</td>\n",
       "      <td>25.75</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>White</td>\n",
       "      <td>...</td>\n",
       "      <td>0.055816</td>\n",
       "      <td>0.188889</td>\n",
       "      <td>1.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.326689</td>\n",
       "      <td>0.423302</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>163</td>\n",
       "      <td>25.416667</td>\n",
       "      <td>Young</td>\n",
       "      <td>1</td>\n",
       "      <td>172.0</td>\n",
       "      <td>74.60</td>\n",
       "      <td>25.216333</td>\n",
       "      <td>24.90</td>\n",
       "      <td>Peru</td>\n",
       "      <td>Indigenous</td>\n",
       "      <td>...</td>\n",
       "      <td>0.065743</td>\n",
       "      <td>0.377778</td>\n",
       "      <td>1.277778</td>\n",
       "      <td>0.344444</td>\n",
       "      <td>0.450827</td>\n",
       "      <td>0.313716</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>158 rows × 181 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Subject        Age AgeGroup  Gender  Height  Weight        BMI  FootLen  \\\n",
       "0          1  33.000000    Young       0   157.5   54.20  21.849332    21.80   \n",
       "1          2  27.583333    Young       0   154.0   44.00  18.552876    22.45   \n",
       "2          3  36.916667    Young       1   161.7   63.40  24.247626    23.10   \n",
       "3          4  61.750000      Old       1   164.0   68.35  25.412701    24.70   \n",
       "4          5  18.333333    Young       0   162.0   56.45  21.509678      NaN   \n",
       "..       ...        ...      ...     ...     ...     ...        ...      ...   \n",
       "153      159  24.750000    Young       0   153.5   62.05  26.334497    21.65   \n",
       "154      160  23.583333    Young       0   161.5   56.55  21.681412    22.75   \n",
       "155      161  25.333333    Young       0   167.7   60.55  21.530198    23.75   \n",
       "156      162  24.083333    Young       1   183.5   63.20  18.769165    25.75   \n",
       "157      163  25.416667    Young       1   172.0   74.60  25.216333    24.90   \n",
       "\n",
       "    Nationality    SkinColor  ...  y_Mean_Resultant_Speed_cop - Closed - Foam  \\\n",
       "0        Brazil       Yellow  ...                                    0.026691   \n",
       "1        Brazil  Pardo/Brown  ...                                    0.037090   \n",
       "2        Brazil        White  ...                                    0.047679   \n",
       "3        Brazil  Pardo/Brown  ...                                    0.066223   \n",
       "4        Brazil        White  ...                                    0.046808   \n",
       "..          ...          ...  ...                                         ...   \n",
       "153      Brazil        White  ...                                    0.038548   \n",
       "154      Brazil        White  ...                                    0.052360   \n",
       "155      Brazil        White  ...                                    0.068107   \n",
       "156      Brazil        White  ...                                    0.055816   \n",
       "157        Peru   Indigenous  ...                                    0.065743   \n",
       "\n",
       "    y_fpcntile50_cop - Closed - Foam y_fpcntile95_cop - Closed - Foam  \\\n",
       "0                           0.177778                         0.844444   \n",
       "1                           0.255556                         0.511111   \n",
       "2                           0.222222                         0.766667   \n",
       "3                           0.166667                         0.577778   \n",
       "4                           0.233333                         0.966667   \n",
       "..                               ...                              ...   \n",
       "153                         0.311111                         0.988889   \n",
       "154                         0.188889                         0.688889   \n",
       "155                         0.377778                         1.177778   \n",
       "156                         0.188889                         1.066667   \n",
       "157                         0.377778                         1.277778   \n",
       "\n",
       "    y_Peaky_Frequency_cop - Closed - Foam  \\\n",
       "0                                0.033333   \n",
       "1                                0.266667   \n",
       "2                                0.111111   \n",
       "3                                0.066667   \n",
       "4                                0.188889   \n",
       "..                                    ...   \n",
       "153                              0.222222   \n",
       "154                              0.033333   \n",
       "155                              0.211111   \n",
       "156                              0.066667   \n",
       "157                              0.344444   \n",
       "\n",
       "     y_Mean_Frequency_cop - Closed - Foam y_Total_power_cop - Closed - Foam  \\\n",
       "0                                0.255995                          0.154036   \n",
       "1                                0.264554                          0.418301   \n",
       "2                                0.280833                          0.512078   \n",
       "3                                0.214622                          1.880497   \n",
       "4                                0.318833                          0.413409   \n",
       "..                                    ...                               ...   \n",
       "153                              0.382401                          0.201918   \n",
       "154                              0.243581                          0.834123   \n",
       "155                              0.421260                          0.516105   \n",
       "156                              0.326689                          0.423302   \n",
       "157                              0.450827                          0.313716   \n",
       "\n",
       "     APA  RPC   SO    DG  \n",
       "0    6.0  4.0  6.0   9.0  \n",
       "1    6.0  4.0  6.0   9.0  \n",
       "2    6.0  6.0  6.0   9.0  \n",
       "3    6.0  6.0  6.0   8.0  \n",
       "4    6.0  6.0  6.0   9.0  \n",
       "..   ...  ...  ...   ...  \n",
       "153  6.0  6.0  6.0  10.0  \n",
       "154  5.0  4.0  6.0   9.0  \n",
       "155  6.0  4.0  6.0   9.0  \n",
       "156  6.0  5.0  6.0   9.0  \n",
       "157  6.0  4.0  6.0  10.0  \n",
       "\n",
       "[158 rows x 181 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base = pd.read_csv(filepath_or_buffer='BDSCLEANED.txt', sep = '\\t')\n",
    "base = base.drop('Unnamed: 0', axis = 1)\n",
    "base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "subtestes={\n",
    "    'APA': 0,\n",
    "    'RPC': 0,\n",
    "    'SO': 0,\n",
    "    'DG': 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = base.drop([ 'Subject', 'AgeGroup','BMI',\n",
    "       'FootLen', 'Nationality', 'SkinColor',\n",
    "       'Ystudy', 'Footwear', 'Illness', 'Illness2', 'Nmedication',\n",
    "       'Medication', 'Ortho-Prosthesis', 'Ortho-Prosthesis2', 'Disability',\n",
    "       'Disability2', 'Falls12m', 'FES_1', 'FES_2', 'FES_3', 'FES_4', 'FES_5',\n",
    "       'FES_6', 'FES_7', 'FES_T', 'FES_S', 'IPAQ_1a', 'IPAQ_1b', 'IPAQ_2a',\n",
    "       'IPAQ_2b', 'IPAQ_3a', 'IPAQ_3b', 'IPAQ_4a', 'IPAQ_4b', 'IPAQ_S',\n",
    "       'TMT_timeA', 'TMT_errorsA', 'TMT_timeB', 'TMT_errorsB', 'Best_1',\n",
    "       'Best_2', 'Best_3l', 'Best_3r', 'Best_4', 'Best_5', 'Best_6l',\n",
    "       'Best_6r', 'Best_7', 'Best_8', 'Best_9', 'Best_10', 'Best_11',\n",
    "       'Best_12', 'Best_13', 'Best_14', 'Best_T','APA','RPC','SO', 'DG'], axis = 1)\n",
    "\n",
    "#FEATURES DO RESNET\n",
    "resnetfeatures = pd.read_csv(filepath_or_buffer='/Users/Nathan/Desktop/Machine Learning/Projeto de Extensão/2020/Outubro/heat_map_encoded.txt', sep = '\\t')\n",
    "resnetfeatures = resnetfeatures.reindex()\n",
    "resnetfeatures.drop('Unnamed: 0',inplace = True, axis = 1)\n",
    "\n",
    "#UNINDO AS FEATURES\n",
    "x = x.join(resnetfeatures)\n",
    "\n",
    "#Normaizando\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "x = scaler.fit_transform(x)\n",
    "\n",
    "x = pd.DataFrame(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#x=x.values\n",
    "from sklearn.model_selection import KFold\n",
    "#faz a separação 90 / 10\n",
    "kf= KFold(n_splits=10)\n",
    "kf.get_n_splits(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################################################\n",
      "SUBTESTE APA\n",
      "################################################\n",
      "################################################\n",
      "SUBTESTE RPC\n",
      "################################################\n",
      "################################################\n",
      "SUBTESTE SO\n",
      "################################################\n",
      "################################################\n",
      "SUBTESTE DG\n",
      "################################################\n"
     ]
    }
   ],
   "source": [
    "for subteste in subtestes:\n",
    "    \n",
    "    print('################################################')\n",
    "    print('SUBTESTE',subteste)\n",
    "    print('################################################')\n",
    "    \n",
    "    y= base[subteste]\n",
    "    \n",
    "    todos_mae=[]\n",
    "    \n",
    "    for train_index, test_index in kf.split(x):\n",
    "        x_train, x_test = x.values[train_index], x.values[test_index] #gera os indices a serem treinados\n",
    "        y_train, y_test = y[train_index], y[test_index] \n",
    "\n",
    "        #print('TREINAMENTO ATUAL:')\n",
    "        #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "\n",
    "        regr=RandomForestRegressor(criterion='mse')\n",
    "        regr.fit(x_train,y_train)\n",
    "\n",
    "        previsoes= regr.predict(x_test)\n",
    "        erro_médio = mean_absolute_error(y_test, previsoes)\n",
    "\n",
    "        #print('Absolute Error:', erro_médio)\n",
    "        \n",
    "        todos_mae.append(erro_médio)\n",
    "\n",
    "    mae_final=0\n",
    "\n",
    "    for n in todos_mae:\n",
    "        mae_final+= (n/ len(todos_mae))\n",
    "            \n",
    "    subtestes[subteste]= mae_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'APA': 0.7587291666666667,\n",
       " 'RPC': 0.9754291666666669,\n",
       " 'SO': 0.6770208333333334,\n",
       " 'DG': 1.2069083333333332}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subtestes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'APA': 0.7262166666666666,\n",
       " 'RPC': 0.9441583333333333,\n",
       " 'SO': 0.6347875000000001,\n",
       " 'DG': 1.1704333333333334}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subtestes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RF PARA A PRIMEIRA PARTE DA MEDIANA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################################################\n",
      "SUBTESTE:  APA\n",
      "Mediana do Best_T 22.0\n",
      "################################################\n",
      "População  75  De 158\n",
      "Previsão [4.06 3.38 2.94 3.98 3.44 3.65 3.34 3.48]\n",
      "Teste [5. 5. 4. 4. 4. 3. 4. 3.]\n",
      "Previsão [3.22 3.52 3.11 3.82 3.8  3.73 3.51 3.13]\n",
      "Teste [3. 4. 2. 4. 4. 5. 5. 4.]\n",
      "Previsão [3.19 3.7  3.42 3.77 3.2  3.21 3.67 3.69]\n",
      "Teste [2. 2. 2. 3. 2. 3. 3. 2.]\n",
      "Previsão [3.46 3.63 3.1  3.69 3.8  2.48 2.83 3.4 ]\n",
      "Teste [4. 2. 3. 4. 2. 3. 2. 4.]\n",
      "Previsão [2.73 2.88 3.13 3.18 3.8  2.83 3.2  3.51]\n",
      "Teste [4. 2. 3. 3. 3. 2. 3. 3.]\n",
      "Previsão [3.44 3.53 3.62 3.97 3.37 3.2  3.92]\n",
      "Teste [3. 3. 4. 4. 4. 3. 3.]\n",
      "Previsão [3.08 3.54 3.19 3.21 3.37 3.55 3.29]\n",
      "Teste [4. 4. 4. 3. 4. 4. 3.]\n",
      "Previsão [2.45 4.16 3.37 3.05 2.95 3.37 3.58]\n",
      "Teste [3. 5. 4. 2. 4. 1. 4.]\n",
      "Previsão [3.44 3.91 3.88 3.13 2.75 3.42 3.17]\n",
      "Teste [4. 4. 5. 5. 3. 3. 4.]\n",
      "Previsão [3.58 3.3  2.97 3.14 3.35 3.74 3.25]\n",
      "Teste [5. 4. 3. 2. 4. 3. 4.]\n",
      "################################################\n",
      "SUBTESTE:  RPC\n",
      "Mediana do Best_T 22.0\n",
      "################################################\n",
      "População  75  De 158\n",
      "################################################\n",
      "SUBTESTE:  SO\n",
      "Mediana do Best_T 22.0\n",
      "################################################\n",
      "População  75  De 158\n",
      "Previsão [5.03 4.67 4.93 5.34 4.57 5.24 4.62 4.66]\n",
      "Teste [4. 4. 4. 6. 5. 4. 6. 5.]\n",
      "Previsão [5.08 4.97 4.88 4.68 4.92 4.64 5.03 4.69]\n",
      "Teste [5. 5. 4. 4. 5. 6. 5. 5.]\n",
      "Previsão [4.39 5.34 4.87 5.12 4.91 4.19 5.02 4.9 ]\n",
      "Teste [5. 5. 5. 4. 5. 5. 6. 3.]\n",
      "Previsão [4.96 4.89 4.67 5.33 5.11 4.7  4.88 4.94]\n",
      "Teste [5. 3. 5. 5. 3. 4. 5. 5.]\n",
      "Previsão [4.86 4.63 4.61 5.05 5.19 4.58 5.09 5.01]\n",
      "Teste [4. 4. 4. 4. 6. 4. 5. 4.]\n",
      "Previsão [4.89 4.39 5.14 5.07 4.83 4.7  4.94]\n",
      "Teste [5. 4. 6. 6. 6. 5. 1.]\n",
      "Previsão [5.14 4.75 5.17 4.6  4.49 5.11 4.97]\n",
      "Teste [5. 5. 6. 5. 6. 5. 6.]\n",
      "Previsão [4.8  4.67 4.93 4.46 4.68 4.79 5.01]\n",
      "Teste [5. 5. 5. 3. 6. 3. 6.]\n",
      "Previsão [4.2  5.37 4.43 4.52 4.6  4.58 4.98]\n",
      "Teste [5. 6. 4. 6. 6. 5. 6.]\n",
      "Previsão [5.24 4.46 4.31 4.99 4.54 4.86 4.49]\n",
      "Teste [6. 4. 5. 5. 6. 5. 5.]\n",
      "################################################\n",
      "SUBTESTE:  DG\n",
      "Mediana do Best_T 22.0\n",
      "################################################\n",
      "População  75  De 158\n"
     ]
    }
   ],
   "source": [
    "for i, subteste in enumerate(subtestes):\n",
    "    \n",
    "    #usando a mediana do BesTest\n",
    "    \n",
    "    X = x.copy()\n",
    "    y = base.copy()\n",
    "    mediana = np.median(base['Best_T'].values)\n",
    "    \n",
    "    # Caso queira usar a mediana do sub teste\n",
    "    \n",
    "    #mediana = np.median(base[subteste].values)\n",
    "    #y = base[subteste].copy()\n",
    "\n",
    "    \n",
    "    print('################################################')\n",
    "    print('SUBTESTE: ',subteste)\n",
    "    #print('Mediana',mediana )\n",
    "    print('Mediana do Best_T', mediana)\n",
    "    print('################################################')\n",
    "    \n",
    "    \n",
    "    #Criando a base de dados abaixo da mediana\n",
    "    #Se for usar a mediana do subteste\n",
    "    \n",
    "    #for n in range(len(base.index)):\n",
    "    #    if y[n] >=mediana:\n",
    "    #        y.drop(labels=n, inplace = True)\n",
    "    #       X.drop(labels=n, inplace = True)\n",
    "    \n",
    "    #Criando a base de dados abaixo da mediana\n",
    "    #Usando a Mediana do Best_T\n",
    "    delete= []\n",
    "    for n in range(len(base.index)):\n",
    "        if y.iloc[n,59] >= mediana:\n",
    "            delete.append(n)\n",
    "            \n",
    "            \n",
    "    y.drop(labels=delete, inplace = True)\n",
    "    X.drop(labels=delete, inplace = True)\n",
    "            \n",
    "    #É necessário resetar o indice, pois o KFOLD precisa dos indices do row sequencialmente dispostos\n",
    "    #Caso use a mediana dos subtestes comente a linha subsequente\n",
    "    \n",
    "    y = y[subteste]\n",
    "    y = y.reset_index()\n",
    "    y.drop('index', inplace= True, axis=1)\n",
    "    y = y.values.ravel()\n",
    "    \n",
    "    \n",
    "    X.reset_index(inplace= True)\n",
    "    X.drop('index', inplace= True, axis=1)\n",
    "    \n",
    "    print('População ', len(X.index), ' De 158') \n",
    "    \n",
    "    #Refazendo o Kfold\n",
    "    \n",
    "    kf= KFold(n_splits=10)\n",
    "    kf.get_n_splits(X)\n",
    "    \n",
    "    todos_mae=[]\n",
    "    \n",
    "    for train_index, test_index in kf.split(X):\n",
    "        x_train, x_test = X.values[train_index], X.values[test_index] #gera os indices a serem treinados\n",
    "        y_train, y_test = y[train_index], y[test_index] \n",
    "\n",
    "        #print('TREINAMENTO ATUAL:')\n",
    "        #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "\n",
    "        regr=RandomForestRegressor(criterion='mse')\n",
    "        regr.fit(x_train,y_train)\n",
    "\n",
    "        previsoes= regr.predict(x_test)\n",
    "        erro_médio = mean_absolute_error(y_test, previsoes)\n",
    "\n",
    "        #print('Absolute Error:', erro_médio)\n",
    "        if subteste in ['APA','SO']:\n",
    "            print('Previsão',previsoes )\n",
    "            print('Teste',y_test )\n",
    "        todos_mae.append(erro_médio)\n",
    "\n",
    "        \n",
    "        todos_mae.append(erro_médio)\n",
    "\n",
    "    mae_final=0\n",
    "    #print(todos_mae)\n",
    "    for n in todos_mae:\n",
    "        mae_final+= (n/ len(todos_mae))\n",
    "    \n",
    "            \n",
    "    subtestes[subteste]= mae_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'APA': 0.7456607142857143,\n",
       " 'RPC': 0.9235535714285714,\n",
       " 'SO': 0.746482142857143,\n",
       " 'DG': 0.9629821428571428}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subtestes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  RF ACIMA DA MEDIANA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################################################\n",
      "SUBTESTE:  APA\n",
      "Mediana do Best_T 22.0\n",
      "################################################\n",
      "População  83  De 158\n",
      "################################################\n",
      "SUBTESTE:  RPC\n",
      "Mediana do Best_T 22.0\n",
      "################################################\n",
      "População  83  De 158\n",
      "################################################\n",
      "SUBTESTE:  SO\n",
      "Mediana do Best_T 22.0\n",
      "################################################\n",
      "População  83  De 158\n",
      "################################################\n",
      "SUBTESTE:  DG\n",
      "Mediana do Best_T 22.0\n",
      "################################################\n",
      "População  83  De 158\n"
     ]
    }
   ],
   "source": [
    "for i, subteste in enumerate(subtestes):\n",
    "    \n",
    "    #usando a mediana do BesTest\n",
    "    \n",
    "    X = x.copy()\n",
    "    y = base.copy()\n",
    "    mediana = np.median(base['Best_T'].values)\n",
    "    \n",
    "    # Caso queira usar a mediana do sub teste\n",
    "    \n",
    "    #mediana = np.median(base[subteste].values)\n",
    "    #y = base[subteste].copy()\n",
    "\n",
    "    \n",
    "    print('################################################')\n",
    "    print('SUBTESTE: ',subteste)\n",
    "    #print('Mediana',mediana )\n",
    "    print('Mediana do Best_T', mediana)\n",
    "    print('################################################')\n",
    "    \n",
    "    \n",
    "    #Criando a base de dados abaixo da mediana\n",
    "    #Se for usar a mediana do subteste\n",
    "    \n",
    "    #for n in range(len(base.index)):\n",
    "    #    if y[n] >=mediana:\n",
    "    #        y.drop(labels=n, inplace = True)\n",
    "    #       X.drop(labels=n, inplace = True)\n",
    "    \n",
    "    #Criando a base de dados abaixo da mediana\n",
    "    #Usando a Mediana do Best_T\n",
    "    delete= []\n",
    "    for n in range(len(base.index)):\n",
    "        if y.iloc[n,59] < mediana:\n",
    "            delete.append(n)\n",
    "            \n",
    "            \n",
    "    y.drop(labels=delete, inplace = True)\n",
    "    X.drop(labels=delete, inplace = True)\n",
    "            \n",
    "    #É necessário resetar o indice, pois o KFOLD precisa dos indices do row sequencialmente dispostos\n",
    "    #Caso use a mediana dos subtestes comente a linha subsequente\n",
    "    \n",
    "    y = y[subteste]\n",
    "    y = y.reset_index()\n",
    "    y.drop('index', inplace= True, axis=1)\n",
    "    y = y.values.ravel()\n",
    "    \n",
    "    \n",
    "    X.reset_index(inplace= True)\n",
    "    X.drop('index', inplace= True, axis=1)\n",
    "    \n",
    "    print('População ', len(X.index), ' De 158') \n",
    "    \n",
    "    #Refazendo o Kfold\n",
    "    \n",
    "    kf= KFold(n_splits=10)\n",
    "    kf.get_n_splits(X)\n",
    "    \n",
    "    todos_mae=[]\n",
    "    \n",
    "    for train_index, test_index in kf.split(X):\n",
    "        x_train, x_test = X.values[train_index], X.values[test_index] #gera os indices a serem treinados\n",
    "        y_train, y_test = y[train_index], y[test_index] \n",
    "\n",
    "        #print('TREINAMENTO ATUAL:')\n",
    "        #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "\n",
    "        regr=RandomForestRegressor(criterion='mse')\n",
    "        regr.fit(x_train,y_train)\n",
    "\n",
    "        previsoes= regr.predict(x_test)\n",
    "        erro_médio = mean_absolute_error(y_test, previsoes)\n",
    "\n",
    "        #print('Absolute Error:', erro_médio)\n",
    "        #if subteste in ['APA','SO']:\n",
    "        #    print('Previsão',previsoes )\n",
    "        #    print('Teste',y_test )\n",
    "        #todos_mae.append(erro_médio)\n",
    "\n",
    "        \n",
    "        todos_mae.append(erro_médio)\n",
    "\n",
    "    mae_final=0\n",
    "    #print(todos_mae)\n",
    "    for n in todos_mae:\n",
    "        mae_final+= (n/ len(todos_mae))\n",
    "    \n",
    "            \n",
    "    subtestes[subteste]= mae_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'APA': 0.5920277777777778,\n",
       " 'RPC': 0.8639027777777777,\n",
       " 'SO': 0.5574305555555555,\n",
       " 'DG': 0.8943472222222223}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subtestes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
